{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b3eef6c",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a> \n",
    " # <p style=\"padding:10px;background-color: #00004d ;margin:10;color: white ;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Ans 1 </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe02d71",
   "metadata": {},
   "source": [
    "Time-dependent seasonal components refer to patterns in a time series where the strength or shape of seasonality changes over time. In other words, the seasonality in the data is not constant but varies across different time periods. This phenomenon is also known as \"seasonal dynamics\" or \"changing seasonality.\"\n",
    "\n",
    "In a time-dependent seasonal component, the regular seasonal patterns (such as daily, weekly, or yearly patterns) are not fixed but exhibit variations due to external factors, trends, or other underlying influences. These variations can lead to challenges in accurately modeling and forecasting the time series.\n",
    "\n",
    "For example, consider retail sales data. If a retail store experiences increased sales during holiday seasons, but the intensity of sales growth during holidays changes from year to year, this would indicate time-dependent seasonal components. In some years, the holiday sales might be exceptionally high, while in others, they could be more modest.\n",
    "\n",
    "In time series analysis, accounting for time-dependent seasonal components requires using more advanced techniques that can capture the changing patterns. Traditional methods like simple seasonal decomposition might not suffice in such cases. Advanced techniques include models that allow for varying seasonality, such as Seasonal-Trend decomposition using LOESS (STL) or models like Prophet, which is designed to handle multiple seasonality and trend changes.\n",
    "\n",
    "In summary, time-dependent seasonal components refer to variations in the strength or shape of seasonality over time in a time series. Recognizing and appropriately modeling these changing patterns is crucial for accurate forecasting and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fbf954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6765e4f4",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> \n",
    " # <p style=\"padding:10px;background-color: #00004d ;margin:10;color: white ;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Ans 2 </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274578fe",
   "metadata": {},
   "source": [
    "Identifying time-dependent seasonal components in time series data involves detecting patterns of seasonality that change over time. This can be a more complex task than identifying regular, stationary seasonal patterns. Here are some steps and techniques that can help identify time-dependent seasonal components:\n",
    "\n",
    "1. **Visual Inspection:** Begin by visually inspecting the time series data. Plot the data over time and observe if there are any noticeable changes in the regular seasonal patterns. Look for instances where the intensity or shape of seasonality appears to vary over different time periods.\n",
    "\n",
    "2. **Seasonal Subseries Plots:** Create seasonal subseries plots by aggregating data for each season separately. If the seasonal patterns change over time, you may see variations in the subseries plots for different time periods.\n",
    "\n",
    "3. **Moving Averages:** Calculate and compare moving averages or rolling averages for different time periods. If the seasonal components are time-dependent, you might observe fluctuations or changes in the moving average values.\n",
    "\n",
    "4. **Autocorrelation and Partial Autocorrelation Functions:** Examine the Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) plots to identify the presence of varying lags of seasonality. Irregular patterns in the ACF and PACF plots can suggest time-dependent seasonal components.\n",
    "\n",
    "5. **Decomposition Techniques:** Apply time series decomposition techniques to separate the time series into its components (trend, seasonality, residuals). Models like Seasonal-Trend decomposition using LOESS (STL) or the seasonal decomposition of time series (S-ETS) can help identify changing patterns.\n",
    "\n",
    "6. **Advanced Models:** Consider using more advanced forecasting models that can capture varying seasonality, such as the Prophet model developed by Facebook, which is designed to handle multiple seasonality and trend changes.\n",
    "\n",
    "7. **Domain Knowledge:** If you have domain knowledge about the data, external factors, or events that could influence changing seasonal patterns, incorporate this information into your analysis.\n",
    "\n",
    "8. **Statistical Tests:** Use statistical tests to assess the presence of significant changes in seasonal patterns over time. This might involve testing for stationarity and changes in variance.\n",
    "\n",
    "It's important to note that identifying time-dependent seasonal components can be challenging, and it may require a combination of techniques and domain expertise. Additionally, different time series data might exhibit varying degrees of time-dependent seasonality. It's always a good practice to combine quantitative analysis with qualitative insights from domain experts to interpret the patterns correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5fccd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ab1708f",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a> \n",
    " # <p style=\"padding:10px;background-color: #00004d ;margin:10;color: white ;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Ans 3 </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9549a1",
   "metadata": {},
   "source": [
    "Time-dependent seasonal components in time series data can be influenced by various factors that cause changes or fluctuations in seasonal patterns over time. Some of the key factors include:\n",
    "\n",
    "1. **Economic Factors:** Changes in economic conditions, such as recessions, booms, or changes in consumer spending habits, can lead to shifts in seasonal patterns. For example, holiday shopping seasons might vary based on economic cycles.\n",
    "\n",
    "2. **Cultural and Social Factors:** Cultural events, holidays, festivals, and societal changes can affect consumer behavior and lead to changes in seasonal patterns. These factors can vary across regions and communities.\n",
    "\n",
    "3. **Technological Advancements:** Technological innovations or shifts in communication and media can impact how people interact and make purchases. These changes can influence the timing and intensity of seasonal demand.\n",
    "\n",
    "4. **Weather and Climate:** Seasonal weather patterns can affect consumer behavior and demand for certain products or services. For example, unseasonably warm or cold weather can influence clothing and energy consumption.\n",
    "\n",
    "5. **Regulatory Changes:** Changes in regulations or policies can influence business operations and consumer behavior, leading to shifts in seasonal patterns. Tax holidays or changes in import/export regulations can impact buying patterns.\n",
    "\n",
    "6. **Supply Chain Disruptions:** Disruptions in the supply chain, such as natural disasters, labor strikes, or transportation issues, can affect the availability of products and impact seasonal patterns.\n",
    "\n",
    "7. **Marketing and Promotions:** Shifts in marketing strategies, promotions, or advertising campaigns can influence consumer behavior and lead to changes in seasonal demand.\n",
    "\n",
    "8. **Demographic Changes:** Changes in demographics, population growth, or shifts in the age distribution of a population can impact consumption patterns and seasonal demand.\n",
    "\n",
    "9. **Competitive Landscape:** Changes in the competitive landscape can affect pricing strategies, product availability, and consumer preferences, leading to variations in seasonal patterns.\n",
    "\n",
    "10. **Global Events:** Major global events, such as the Olympics, World Cup, or health pandemics, can disrupt normal consumption patterns and influence seasonal behavior.\n",
    "\n",
    "11. **Cyclical Trends:** Long-term economic and societal cycles can influence consumer spending patterns and lead to changes in seasonal demand.\n",
    "\n",
    "It's important to consider these factors when analyzing time-dependent seasonal components in time series data. Understanding the underlying causes of changing seasonal patterns can help businesses and analysts make more accurate forecasts and adapt to evolving consumer behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21c9b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4587b56",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a> \n",
    " # <p style=\"padding:10px;background-color: #00004d ;margin:10;color: white ;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Ans 4 </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd28b938",
   "metadata": {},
   "source": [
    "Autoregression (AR) models are widely used in time series analysis and forecasting to capture and model the relationship between a time series and its own lagged values. In other words, an autoregressive model predicts the value of a variable at a certain time point based on its own past values.\n",
    "\n",
    "The basic idea behind autoregression is that the current value of a time series can be explained by its past values, with the assumption that the relationship between these values remains relatively consistent over time. AR models are particularly useful for capturing short-term dependencies and patterns in time series data.\n",
    "\n",
    "Here's how autoregression models are used in time series analysis and forecasting:\n",
    "\n",
    "1. **Modeling Autocorrelation:** Autoregressive models quantify the autocorrelation in a time series. Autocorrelation refers to the correlation between a variable and its lagged values. By modeling autocorrelation, AR models can capture patterns that repeat over time.\n",
    "\n",
    "2. **Model Representation:** An autoregressive model of order \\(p\\), denoted as AR(p), uses the past \\(p\\) values of the time series to predict its current value. Mathematically, an AR(p) model can be represented as:\n",
    "   \n",
    "   \\[y_t = c + ϕ_1 * y_{t-1} + ϕ_2 * y_{t-2} + ... + ϕ_p * y_{t-p} + ε_t\\]\n",
    "\n",
    "   Where:\n",
    "   - \\(y_t\\) is the current value of the time series at time \\(t\\).\n",
    "   - \\(c\\) is a constant term.\n",
    "   - \\( ϕ_1, ϕ_2, ..., ϕ_p\\) are the autoregressive coefficients.\n",
    "   - \\(y_{t-1}, y_{t-2}, ...., y_{t-p}\\) are the lagged values of the time series.\n",
    "   - \\( ε_t \\) is the white noise term representing random noise at time \\(t\\).\n",
    "\n",
    "3. **Parameter Estimation:** The autoregressive coefficients \\( ϕ_1, ϕ_2, ..., ϕ_p\\) are estimated using techniques like the method of least squares or maximum likelihood estimation. The choice of \\(p\\) determines how many lagged values are considered in the model.\n",
    "\n",
    "4. **Model Selection:** Determining the optimal order \\(p\\) for the AR model is important. This can be achieved using techniques such as AIC (Akaike Information Criterion), BIC (Bayesian Information Criterion), or cross-validation.\n",
    "\n",
    "5. **Forecasting:** Once the AR model is trained and the coefficients are estimated, it can be used to make short-term forecasts of future values. The model predicts the next value based on the most recent \\(p\\) observed values.\n",
    "\n",
    "6. **Model Evaluation:** The performance of the AR model is evaluated using various metrics, such as Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), or forecasting accuracy measures.\n",
    "\n",
    "7. **Limitations:** AR models are best suited for capturing short-term dependencies and may not perform well if the time series has long-term trends or complex patterns that the autoregressive relationships alone cannot capture.\n",
    "\n",
    "Autoregressive models are an essential tool in time series analysis, especially when there's a strong autocorrelation pattern in the data. They provide a simple yet effective approach to modeling and forecasting time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edd80e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc7feefc",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a> \n",
    " # <p style=\"padding:10px;background-color: #00004d ;margin:10;color: white ;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Ans 5 </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40ce504",
   "metadata": {},
   "source": [
    "Autoregression (AR) models are used to make predictions for future time points by utilizing the relationship between the current value of a time series and its past values. The idea is to use the past observed values of the time series to forecast its future values. Here's how you can use autoregression models to make predictions:\n",
    "\n",
    "1. **Choose the Order (p) of the AR Model:** The first step is to determine the order of the autoregressive model, denoted as \\(p\\). This order specifies how many lagged values of the time series will be used to predict the current value. The choice of \\(p\\) depends on the nature of the data and can be determined through techniques like AIC, BIC, or cross-validation.\n",
    "\n",
    "2. **Data Preparation:** Organize your time series data into a format suitable for modeling. This typically involves splitting the data into a training set and a test set. The training set is used to estimate the autoregressive coefficients, while the test set is used to evaluate the performance of the model.\n",
    "\n",
    "3. **Estimate Coefficients:** Use the training data to estimate the autoregressive coefficients\\( ϕ_1, ϕ_2, ..., ϕ_p\\)  of the AR model. This can be done through methods like the method of least squares or maximum likelihood estimation.\n",
    "\n",
    "4. **Forecasting:** To make predictions for future time points, follow these steps:\n",
    "   - Start with the most recent \\(p\\) observed values from the training set (or the test set, if you're making out-of-sample predictions).\n",
    "   - Plug in these lagged values into the AR model equation:\n",
    "   \n",
    "   \\[y_t = c + ϕ_1 * y_{t-1} + ϕ_2 * y_{t-2} + ... + ϕ_p * y_{t-p} + ε_t\\]\n",
    "   \n",
    "   - Calculate the forecasted value \\(y_t\\) for the next time point.\n",
    "\n",
    "5. **Iterate:** As new observations become available, update the lagged values and continue forecasting for subsequent time points.\n",
    "\n",
    "6. **Model Evaluation:** After forecasting, compare the predicted values with the actual values from the test set to evaluate the accuracy of the AR model's predictions. Common evaluation metrics include Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and forecasting accuracy measures.\n",
    "\n",
    "7. **Visualization:** Visualize the predicted values along with the actual values to understand how well the model captures the underlying patterns and trends in the time series.\n",
    "\n",
    "8. **Future Predictions:** Once the model is validated, you can use it to make predictions for future time points beyond the test set.\n",
    "\n",
    "Keep in mind that while AR models are effective for capturing short-term dependencies and autocorrelation patterns, they may not perform well when dealing with long-term trends, seasonality, or more complex patterns. In such cases, more advanced models like ARIMA (AutoRegressive Integrated Moving Average) or state-of-the-art approaches may be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38cc8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e113490f",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a> \n",
    " # <p style=\"padding:10px;background-color: #00004d ;margin:10;color: white ;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Ans 6 </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4209a568",
   "metadata": {},
   "source": [
    "A Moving Average (MA) model is a time series model used in forecasting that focuses on the relationship between the current value of a time series and the past forecast errors (also known as residuals). It's a part of the broader category of autoregressive integrated moving average (ARIMA) models, which combine autoregressive (AR) and moving average (MA) components.\n",
    "\n",
    "The MA model is characterized by the following components:\n",
    "\n",
    "1. **MA Order (q):** The order of the MA model is denoted as \\(q\\), and it represents the number of lagged forecast errors that are included in the model. Each lag corresponds to a previous time point's forecast error. A higher \\(q\\) value includes more past errors in the model.\n",
    "\n",
    "2. **Formula:** The formula for an MA(q) model is as follows:\n",
    "\n",
    "   \\[y_t = μ  + ε_t + θ_1 *  ε_{t-1} + θ_2 * ε_{t-2} + .... + θ_q * ε_{t-q}\\]\n",
    "   \n",
    "   where \\(y_t\\) is the current value of the time series, \\(\\mu\\) is the mean of the series, \\(ε_t\\) is the error term at time \\(t\\), and \\(θ_1,  θ_2, .... ,  θ_q\\) are the parameters to be estimated.\n",
    "\n",
    "3. **Estimation:** The parameters\\(θ_1,  θ_2, .... ,  θ_q\\)  are estimated using methods such as least squares or maximum likelihood estimation. These parameters determine the weights assigned to the lagged forecast errors in order to predict the current value.\n",
    "\n",
    "4. **Interpretation:** The coefficients \\(θ_1,  θ_2, .... ,  θ_q\\)  represent the impact of past forecast errors on the current value. A positive coefficient indicates that a positive (negative) forecast error in the past leads to an increase (decrease) in the current value.\n",
    "\n",
    "5. **Forecasting:** To make forecasts, the MA model uses the lagged forecast errors to adjust the prediction based on the error patterns observed in the past. As new data becomes available, the model continues to use the most recent forecast errors to update its predictions.\n",
    "\n",
    "6. **Model Selection:** Similar to ARIMA models, the appropriate order of the MA model (\\(q\\)) needs to be determined. This can be done using techniques like examining autocorrelation and partial autocorrelation plots, and using information criteria (e.g., AIC, BIC).\n",
    "\n",
    "7. **Limitations:** MA models are most effective when the underlying process generating the time series is driven by past forecast errors. They may not perform well when dealing with more complex time series patterns like trends, seasonality, or long-term dependencies.\n",
    "\n",
    "MA models are often combined with autoregressive (AR) components to create ARMA models or integrated with differencing to create ARIMA models, allowing for a more comprehensive approach to time series forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c207b2e2",
   "metadata": {},
   "source": [
    "The Moving Average (MA) model is just one type of time series model, and it differs from other models like autoregressive (AR) models, integrated models (I), and their combinations (ARMA and ARIMA) in terms of how it considers past information and forecast errors to make predictions.\n",
    "\n",
    "Here are some key differences between the MA model and other time series models:\n",
    "\n",
    "1. **AR Model (Autoregressive):**\n",
    "   - In an AR model, the current value of the time series depends on its own past values (lags).\n",
    "   - AR models use autoregressive terms, where the current value is a linear combination of its own lagged values with coefficients.\n",
    "   - The AR model captures patterns in the time series by relating it to its own past, assuming that past values have predictive power.\n",
    "\n",
    "2. **ARMA Model (Autoregressive Moving Average):**\n",
    "   - The ARMA model combines both autoregressive (AR) and moving average (MA) components.\n",
    "   - It considers both the relationship between the time series and its own past values (AR) as well as the relationship between the time series and past forecast errors (MA).\n",
    "   - ARMA models are versatile and can capture various patterns in the time series.\n",
    "\n",
    "3. **ARIMA Model (Autoregressive Integrated Moving Average):**\n",
    "   - The ARIMA model extends the ARMA model by including a differencing step to handle non-stationary time series.\n",
    "   - The differencing component helps remove trends and make the time series stationary before applying the ARMA model.\n",
    "   - ARIMA models are suitable for time series with trends and seasonality.\n",
    "\n",
    "4. **MA Model (Moving Average):**\n",
    "   - The MA model focuses on modeling the relationship between the current value of the time series and past forecast errors (residuals).\n",
    "   - It does not consider the time series' own past values, only the patterns in past errors.\n",
    "   - The MA model is effective when forecast errors are informative and have predictive power.\n",
    "\n",
    "In summary, the primary distinction of the MA model is its emphasis on utilizing past forecast errors for prediction. Other models like AR, ARMA, and ARIMA incorporate the time series' own past values and may also include the effects of past errors to capture a broader range of patterns. The choice of model depends on the specific characteristics of the time series data, such as the presence of trends, seasonality, and the nature of the underlying patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974c4ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c84e5f74",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a> \n",
    " # <p style=\"padding:10px;background-color: #00004d ;margin:10;color: white ;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Ans 7 </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fbea4c",
   "metadata": {},
   "source": [
    "A mixed Autoregressive Moving Average (ARMA) model is a time series model that combines both autoregressive (AR) and moving average (MA) components to capture the relationships and patterns in a time series. It is a more general model that can handle various types of time series data with both autoregressive and moving average behaviors.\n",
    "\n",
    "In a mixed ARMA model, the time series data is modeled as a combination of its own past values (AR terms) and past forecast errors (MA terms). The AR terms capture the dependence of the current value on its own lagged values, while the MA terms capture the relationship between the current value and past forecast errors.\n",
    "\n",
    "The notation for a mixed ARMA model is ARMA(p, q), where:\n",
    "- \"p\" is the order of the autoregressive component (number of lagged values to consider).\n",
    "- \"q\" is the order of the moving average component (number of past forecast errors to consider).\n",
    "\n",
    "A mixed ARMA model can capture a wide range of time series patterns, such as trends, seasonality, and other dependencies. It's particularly useful when the time series exhibits both autoregressive behavior (dependence on its own past values) and moving average behavior (dependence on past forecast errors).\n",
    "\n",
    "Mixed ARMA models are commonly used in time series analysis and forecasting to capture the underlying dynamics of the data and make accurate predictions for future values. They can be used for both stationary and non-stationary time series, and their parameters are estimated using techniques like maximum likelihood estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2140a8e",
   "metadata": {},
   "source": [
    "An AR (Autoregressive) model and an MA (Moving Average) model are specific types of time series models that focus on capturing specific patterns in a time series data. A mixed ARMA (Autoregressive Moving Average) model is a combination of both AR and MA components, allowing it to capture a broader range of patterns and dependencies in the data.\n",
    "\n",
    "Here's how they differ:\n",
    "\n",
    "1. Autoregressive (AR) Model:\n",
    "   - An AR model represents the current value of a time series as a linear combination of its own past values (lags).\n",
    "   - It captures the autoregressive behavior, where the current value depends on its own past values with different weights.\n",
    "   - Notation: AR(p), where \"p\" is the order of the model (number of lags considered).\n",
    "   - Useful for capturing trend-like patterns in the data.\n",
    "\n",
    "2. Moving Average (MA) Model:\n",
    "   - An MA model represents the current value of a time series as a linear combination of past forecast errors (residuals).\n",
    "   - It captures the moving average behavior, where the current value depends on past forecast errors with different weights.\n",
    "   - Notation: MA(q), where \"q\" is the order of the model (number of past forecast errors considered).\n",
    "   - Useful for capturing short-term fluctuations or noise in the data.\n",
    "\n",
    "3. Mixed ARMA Model:\n",
    "   - A mixed ARMA model combines both autoregressive and moving average components in a single model.\n",
    "   - It captures a broader range of patterns, including autoregressive dependencies and moving average behavior.\n",
    "   - Notation: ARMA(p, q), where \"p\" is the order of the autoregressive component and \"q\" is the order of the moving average component.\n",
    "   - Useful for capturing complex time series patterns that involve both trend-like behavior and short-term fluctuations.\n",
    "\n",
    "In summary, an AR model focuses on modeling the autoregressive behavior of a time series, an MA model focuses on modeling short-term fluctuations, and a mixed ARMA model combines both behaviors to provide a more comprehensive representation of the underlying dynamics of the data. The choice of model depends on the specific patterns present in the data and the goals of the analysis or forecasting task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4441d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7be7eac8",
   "metadata": {},
   "source": [
    "<a id=\"9\"></a> \n",
    " # <p style=\"padding:10px;background-color: #01DFD7 ;margin:10;color: white ;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">END</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34e6bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6abe77a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1376e3bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6245dba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba83216d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534de72a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773c99a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57b8b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
