{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c681963",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a> \n",
    " # <p style=\"padding:10px;background-color: #00004d ;margin:10;color: white ;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Ans 1 </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6fa48e",
   "metadata": {},
   "source": [
    "In machine learning, kernel functions play a significant role in various algorithms, particularly in Support Vector Machines (SVMs). Kernel functions enable us to transform data from the input space to a higher-dimensional feature space without explicitly computing the transformed feature vectors. Polynomial functions are a specific type of kernel function used for this purpose.\n",
    "\n",
    "The relationship between polynomial functions and kernel functions lies in the fact that polynomial kernels are a type of kernel function used in SVMs to implicitly map the data into a higher-dimensional space. Polynomial kernels are used to capture nonlinear relationships in the data without actually computing the coordinates of the data points in the higher-dimensional space. Instead, they compute the dot product between the data points in the original space, as if they were mapped into the higher-dimensional space.\n",
    "\n",
    "Mathematically, the polynomial kernel function is defined as:\n",
    "\n",
    "\\[ K(x, x') = (x.T x' + c)^d \\]\n",
    "\n",
    "Where:\n",
    "- \\( x \\) and \\( x' \\) are data points.\n",
    "- \\( c \\) is a constant (typically 0 or 1) representing the intercept term.\n",
    "- \\( d \\) is the degree of the polynomial.\n",
    "\n",
    "The polynomial kernel can capture complex relationships in the data by considering interactions between features up to the specified degree \\( d \\). Higher degrees can capture more intricate nonlinear relationships, but they may also lead to overfitting.\n",
    "\n",
    "The key advantage of kernel functions, including polynomial kernels, is that they allow SVMs to learn complex decision boundaries in the feature space without explicitly computing the coordinates of the mapped data points. This is achieved by working with dot products between the data points in the higher-dimensional space.\n",
    "\n",
    "In summary, the relationship between polynomial functions and kernel functions is that polynomial kernels are a specific type of kernel function used in machine learning algorithms, particularly in SVMs, to transform data into a higher-dimensional space and capture nonlinear relationships between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab02af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3e90cb0",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> \n",
    " # <p style=\"padding:10px;background-color: #00004d ;margin:10;color: white ;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Ans 2 </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac75f280",
   "metadata": {},
   "source": [
    "Implementing an SVM with a polynomial kernel using Scikit-learn is straightforward. Scikit-learn provides the `SVC` (Support Vector Classification) class that allows you to easily specify different kernel functions, including polynomial kernels. Here's how you can implement an SVM with a polynomial kernel in Python using Scikit-learn:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a83090",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d34f2caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features\n",
    "y = iris.target  # Labels\n",
    "\n",
    "# Split the dataset into a training set and a testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier with a polynomial kernel\n",
    "svm_poly = SVC(kernel='poly', degree=3)  # You can adjust the degree as needed\n",
    "\n",
    "# Train the classifier on the training set\n",
    "svm_poly.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for the testing set\n",
    "y_pred = svm_poly.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d062266",
   "metadata": {},
   "source": [
    "In this example, the `SVC` class is used to create an SVM classifier with a polynomial kernel. The `kernel` parameter is set to `'poly'`, and you can adjust the `degree` parameter to specify the degree of the polynomial kernel. Higher degrees capture more complex relationships but may also lead to overfitting.\n",
    "\n",
    "After training the classifier, you can predict labels for the testing set and calculate the accuracy using the `accuracy_score` function from Scikit-learn's `metrics` module.\n",
    "\n",
    "Remember that the Iris dataset might not be the best fit for demonstrating the effectiveness of polynomial kernels, as it is relatively simple and linearly separable. Polynomial kernels are more useful when dealing with more complex datasets that have nonlinear decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66735745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee80ca96",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a> \n",
    " # <p style=\"padding:10px;background-color: #00004d ;margin:10;color: white ;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Ans 3 </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b861d3",
   "metadata": {},
   "source": [
    "In Support Vector Regression (SVR), the parameter \\( \\epsilon \\) (epsilon) is a crucial hyperparameter that determines the width of the margin around the predicted function. It essentially defines the zone within which errors (deviations from the target values) are tolerated. The impact of increasing the value of \\( \\epsilon \\) on the number of support vectors in SVR is as follows:\n",
    "\n",
    "1. **Smaller \\( ϵ \\)**: When \\( ϵ \\) is small, SVR aims to fit the data points as accurately as possible. This can lead to a narrower margin and a higher potential for the data points to be considered support vectors. As a result, the number of support vectors may increase because SVR tries to minimize the deviations from the target values for each data point. This could potentially lead to overfitting if the model becomes too complex.\n",
    "\n",
    "2. **Larger \\( ϵ \\)**: When \\( ϵ \\) is large, SVR allows for a wider margin and greater tolerance for errors. In this case, data points that fall within the margin (within \\( ϵ \\) distance from the predicted function) are not treated as support vectors, even if they deviate from the target values. As \\( ϵ \\) increases, fewer data points are likely to be classified as support vectors, as the model is more focused on capturing the general trend rather than fitting each individual point.\n",
    "\n",
    "In summary, increasing the value of \\( ϵ \\) in SVR tends to decrease the number of support vectors by allowing a wider margin and accommodating a higher level of error tolerance. This can lead to a more generalized model that captures the overall trend rather than fitting noise in the data. However, the appropriate choice of \\( ϵ \\) depends on the nature of the data, the problem, and the desired trade-off between model complexity and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57c8376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "924c80c3",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a> \n",
    " # <p style=\"padding:10px;background-color: #00004d ;margin:10;color: white ;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Ans 4 </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540db19f",
   "metadata": {},
   "source": [
    "The performance of Support Vector Regression (SVR) is influenced by several key parameters: the choice of kernel function, the \\( C \\) parameter, the \\(  ϵ \\) parameter, and the \\( γ  \\) parameter (if applicable, depending on the kernel). Let's discuss how each of these parameters affects the performance of SVR:\n",
    "\n",
    "1. **Choice of Kernel Function**:\n",
    "   - **Linear Kernel**: A linear kernel assumes a linear relationship between features and target values. It works well when the data has a linear structure.\n",
    "   - **Polynomial Kernel**: A polynomial kernel captures higher-degree interactions between features. Higher polynomial degrees can lead to overfitting.\n",
    "   - **RBF (Radial Basis Function) Kernel**: An RBF kernel is suitable for capturing nonlinear relationships. Smaller \\( γ \\) values lead to smoother curves, while larger \\( γ \\) values can result in more complex, wiggly curves. Overfitting can occur with high \\( γ \\) values.\n",
    "   - **Sigmoid Kernel**: A sigmoid kernel captures S-shaped relationships. It's sensitive to the \\( γ \\) and coefficient parameters.\n",
    "\n",
    "2. **C Parameter**:\n",
    "   - The \\( C \\) parameter controls the trade-off between maximizing the margin (large \\( C \\)) and minimizing the error (small \\( C \\)).\n",
    "   - Smaller \\( C \\) values allow more errors (soft margin) but reduce the risk of overfitting.\n",
    "   - Larger \\( C \\) values make the margin narrower, leading to fewer support vectors and potentially overfitting if \\( C \\) is too large.\n",
    "\n",
    "3. **Epsilon (\\(  ϵ \\)) Parameter**:\n",
    "   - The \\(  ϵ \\) parameter defines the width of the margin around the predicted function.\n",
    "   - Smaller \\(  ϵ \\) values result in a narrower margin, leading to potentially more support vectors and accurate fitting to individual data points.\n",
    "   - Larger \\(  ϵ \\) values result in a wider margin, leading to fewer support vectors and a more generalized model.\n",
    "\n",
    "4. **Gamma (\\( γ \\)) Parameter** (For RBF and Polynomial Kernels):\n",
    "   - The \\( γ \\) parameter determines the shape of the kernel function's curve.\n",
    "   - Smaller \\( γ \\) values create smoother, broader curves, which can lead to underfitting.\n",
    "   - Larger \\( γ \\) values create sharper, narrower curves, which can lead to overfitting.\n",
    "\n",
    "Overall, the performance of SVR is highly dependent on finding the right balance among these parameters. Choosing the appropriate kernel function and parameter values requires experimentation, validation, and cross-validation. In practice, it's important to tune these parameters using techniques like grid search or randomized search to find the combination that results in the best performance on unseen data. Additionally, domain knowledge and understanding the nature of the data are crucial for making informed decisions about parameter choices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee523a1",
   "metadata": {},
   "source": [
    "Certainly! Let's go through each parameter in Support Vector Regression (SVR), understand how it works, and discuss scenarios when you might want to increase or decrease its value.\n",
    "\n",
    "1. **Choice of Kernel Function**:\n",
    "   - **Linear Kernel**: Works with linear relationships between features and target values. Use it when you believe the data has a simple linear structure, and you want a straightforward model.\n",
    "   - **Polynomial Kernel**: Captures higher-degree interactions between features. Increase the degree for more complex relationships, but be cautious of overfitting.\n",
    "   - **RBF Kernel**: Suitable for capturing nonlinear relationships. Increase \\( γ \\) for more localized decision boundaries, but be careful of overfitting with high \\( γ \\) values.\n",
    "   - **Sigmoid Kernel**: Suitable for S-shaped relationships. It's sensitive to \\( γ \\) and coefficient parameters. It might be useful for specific scenarios, but be cautious of its behavior.\n",
    "\n",
    "2. **C Parameter**:\n",
    "   - Controls the trade-off between margin and error.\n",
    "   - Increase \\( C \\) (use larger values):\n",
    "     - When you prioritize fitting the training data closely.\n",
    "     - When you suspect the data has minimal noise and overfitting is not a concern.\n",
    "   - Decrease \\( C \\) (use smaller values):\n",
    "     - When you want a larger margin and allow more errors (soft margin).\n",
    "     - When you want to reduce the risk of overfitting and prioritize generalization.\n",
    "\n",
    "3. **Epsilon (\\( ϵ \\)) Parameter**:\n",
    "   - Defines the width of the margin around the predicted function.\n",
    "   - Decrease \\( ϵ \\) (use smaller values):\n",
    "     - When you want a narrow margin and accurate fitting to individual data points.\n",
    "     - When you are confident in the accuracy of your data and want a precise model.\n",
    "   - Increase \\( ϵ \\) (use larger values):\n",
    "     - When you want a wider margin and a more generalized model.\n",
    "     - When you want to reduce the influence of individual data points and potential noise.\n",
    "\n",
    "4. **Gamma (\\( γ \\)) Parameter** (For RBF and Polynomial Kernels):\n",
    "   - Controls the shape of the kernel function's curve.\n",
    "   - Increase \\( γ \\) (use larger values):\n",
    "     - When you want sharper, narrower curves.\n",
    "     - When you believe the data has complex and localized relationships.\n",
    "     - Be cautious of overfitting, as high \\( γ \\) values can lead to fitting noise.\n",
    "   - Decrease \\( γ \\) (use smaller values):\n",
    "     - When you want smoother, broader curves.\n",
    "     - When you believe the data has more global relationships.\n",
    "     - Be cautious of underfitting, as very low \\( γ \\) values might oversmooth the model.\n",
    "\n",
    "In practice, parameter tuning is often performed through techniques like grid search or randomized search. Cross-validation helps you evaluate the model's performance with different parameter values and select the combination that generalizes well to new, unseen data. Domain knowledge and understanding the nature of your data guide your choices for parameter adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3711f5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45a0a568",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a> \n",
    " # <p style=\"padding:10px;background-color: #00004d ;margin:10;color: white ;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Ans 5 </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2634cd66",
   "metadata": {},
   "source": [
    "Let's use the Breast Cancer Wisconsin (Diagnostic) dataset, which is available in Scikit-learn and is commonly used for binary classification tasks. This dataset contains features computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. The task is to predict whether a breast mass is malignant (cancerous) or benign (non-cancerous)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23ef363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8c55066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a DataFrame with features and target\n",
    "columns = cancer.feature_names.tolist() + ['target']\n",
    "data = pd.DataFrame(data=X, columns=columns[:-1])\n",
    "data['target'] = y\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d9d8279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455, 30), (114, 30), (455,), (114,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "972156ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.418864</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0.435214</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.222878</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.483590</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>0.213433</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.776263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385928</td>\n",
       "      <td>0.241347</td>\n",
       "      <td>0.094008</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>0.814012</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773711</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>0.430351</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.378283</td>\n",
       "      <td>0.186816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123934</td>\n",
       "      <td>0.506948</td>\n",
       "      <td>0.341575</td>\n",
       "      <td>0.437364</td>\n",
       "      <td>0.172415</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.142595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0     0.521037      0.022658        0.545989   0.363733         0.593753   \n",
       "1     0.643144      0.272574        0.615783   0.501591         0.289880   \n",
       "2     0.601496      0.390260        0.595743   0.449417         0.514309   \n",
       "3     0.210090      0.360839        0.233501   0.102906         0.811321   \n",
       "4     0.629893      0.156578        0.630986   0.489290         0.430351   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0          0.792037        0.703140             0.731113       0.686364   \n",
       "1          0.181768        0.203608             0.348757       0.379798   \n",
       "2          0.431017        0.462512             0.635686       0.509596   \n",
       "3          0.811361        0.565604             0.522863       0.776263   \n",
       "4          0.347893        0.463918             0.518390       0.378283   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                0.605518  ...       0.141525         0.668310    0.450698   \n",
       "1                0.141323  ...       0.303571         0.539818    0.435214   \n",
       "2                0.211247  ...       0.360075         0.508442    0.374508   \n",
       "3                1.000000  ...       0.385928         0.241347    0.094008   \n",
       "4                0.186816  ...       0.123934         0.506948    0.341575   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0          0.601136           0.619292         0.568610              0.912027   \n",
       "1          0.347553           0.154563         0.192971              0.639175   \n",
       "2          0.483590           0.385375         0.359744              0.835052   \n",
       "3          0.915472           0.814012         0.548642              0.884880   \n",
       "4          0.437364           0.172415         0.319489              0.558419   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0        0.598462                 0.418864       0  \n",
       "1        0.233590                 0.222878       0  \n",
       "2        0.403706                 0.213433       0  \n",
       "3        1.000000                 0.773711       0  \n",
       "4        0.157500                 0.142595       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a MinMaxScaler instance\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the features\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "\n",
    "# Create a DataFrame with scaled features and target\n",
    "scaled_data = pd.DataFrame(data=scaled_X, columns=columns[:-1])\n",
    "scaled_data['target'] = y\n",
    "\n",
    "# Display the first few rows of the scaled DataFrame\n",
    "scaled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0da67800",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the features\n",
    "X_train_scaled= scaler.fit_transform(X_train)\n",
    "X_test_scaled= scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b8892de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create an instance of the SVC classifier\n",
    "svc_classifier = SVC()\n",
    "\n",
    "# Train the classifier on the scaled training data\n",
    "svc_classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a64b782d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels :  [1 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
      " 1 1 0]\n",
      "\n",
      "Actual labels :  [1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
      " 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Predict labels for the scaled testing data\n",
    "y_pred = svc_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Display the predicted labels\n",
    "print(\"Predicted labels : \", y_pred)\n",
    "print(\"\\nActual labels : \", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a714d1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9736842105263158\n",
      "Precision: 0.9722222222222222\n",
      "Recall: 0.9859154929577465\n",
      "F1-score: 0.979020979020979\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Display the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0929bcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best Score: 0.9802197802197803\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV instance\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV to the scaled training data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "789ecd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best tuned parameters from the grid search results\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Create a tuned SVC classifier using the best parameters\n",
    "tuned_svc_classifier = SVC(**best_params)\n",
    "\n",
    "# Train the tuned classifier on the entire scaled dataset\n",
    "tuned_svc_classifier.fit(scaled_X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5f560ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained classifier saved to tuned_svc_classifier.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained classifier to a file using pickle\n",
    "filename = 'tuned_svc_classifier.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(tuned_svc_classifier, file)\n",
    "\n",
    "print(\"Trained classifier saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8274d0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained classifier loaded from tuned_svc_classifier.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load the trained classifier from the file using pickle\n",
    "loaded_tuned_svc_classifier = None\n",
    "with open(filename, 'rb') as file:\n",
    "    loaded_tuned_svc_classifier = pickle.load(file)\n",
    "\n",
    "print(\"Trained classifier loaded from\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce192cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_tuned_svc_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab4622b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9da753a",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a> \n",
    " # <p style=\"padding:10px;background-color: #01DFD7 ;margin:10;color: white ;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">END</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a385f76c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2386e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af09f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac420e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d28eef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
