{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.2567\n",
      "Epoch [2/100], Loss: 1.1542\n",
      "Epoch [3/100], Loss: 1.0668\n",
      "Epoch [4/100], Loss: 0.9930\n",
      "Epoch [5/100], Loss: 0.9296\n",
      "Epoch [6/100], Loss: 0.8734\n",
      "Epoch [7/100], Loss: 0.8214\n",
      "Epoch [8/100], Loss: 0.7723\n",
      "Epoch [9/100], Loss: 0.7262\n",
      "Epoch [10/100], Loss: 0.6833\n",
      "Epoch [11/100], Loss: 0.6438\n",
      "Epoch [12/100], Loss: 0.6077\n",
      "Epoch [13/100], Loss: 0.5753\n",
      "Epoch [14/100], Loss: 0.5464\n",
      "Epoch [15/100], Loss: 0.5208\n",
      "Epoch [16/100], Loss: 0.4976\n",
      "Epoch [17/100], Loss: 0.4764\n",
      "Epoch [18/100], Loss: 0.4568\n",
      "Epoch [19/100], Loss: 0.4388\n",
      "Epoch [20/100], Loss: 0.4224\n",
      "Epoch [21/100], Loss: 0.4077\n",
      "Epoch [22/100], Loss: 0.3945\n",
      "Epoch [23/100], Loss: 0.3825\n",
      "Epoch [24/100], Loss: 0.3714\n",
      "Epoch [25/100], Loss: 0.3610\n",
      "Epoch [26/100], Loss: 0.3513\n",
      "Epoch [27/100], Loss: 0.3423\n",
      "Epoch [28/100], Loss: 0.3338\n",
      "Epoch [29/100], Loss: 0.3260\n",
      "Epoch [30/100], Loss: 0.3187\n",
      "Epoch [31/100], Loss: 0.3120\n",
      "Epoch [32/100], Loss: 0.3060\n",
      "Epoch [33/100], Loss: 0.3006\n",
      "Epoch [34/100], Loss: 0.2954\n",
      "Epoch [35/100], Loss: 0.2907\n",
      "Epoch [36/100], Loss: 0.2864\n",
      "Epoch [37/100], Loss: 0.2824\n",
      "Epoch [38/100], Loss: 0.2787\n",
      "Epoch [39/100], Loss: 0.2752\n",
      "Epoch [40/100], Loss: 0.2718\n",
      "Epoch [41/100], Loss: 0.2685\n",
      "Epoch [42/100], Loss: 0.2654\n",
      "Epoch [43/100], Loss: 0.2625\n",
      "Epoch [44/100], Loss: 0.2598\n",
      "Epoch [45/100], Loss: 0.2573\n",
      "Epoch [46/100], Loss: 0.2549\n",
      "Epoch [47/100], Loss: 0.2525\n",
      "Epoch [48/100], Loss: 0.2501\n",
      "Epoch [49/100], Loss: 0.2478\n",
      "Epoch [50/100], Loss: 0.2454\n",
      "Epoch [51/100], Loss: 0.2432\n",
      "Epoch [52/100], Loss: 0.2410\n",
      "Epoch [53/100], Loss: 0.2391\n",
      "Epoch [54/100], Loss: 0.2373\n",
      "Epoch [55/100], Loss: 0.2357\n",
      "Epoch [56/100], Loss: 0.2341\n",
      "Epoch [57/100], Loss: 0.2327\n",
      "Epoch [58/100], Loss: 0.2314\n",
      "Epoch [59/100], Loss: 0.2302\n",
      "Epoch [60/100], Loss: 0.2291\n",
      "Epoch [61/100], Loss: 0.2281\n",
      "Epoch [62/100], Loss: 0.2272\n",
      "Epoch [63/100], Loss: 0.2262\n",
      "Epoch [64/100], Loss: 0.2253\n",
      "Epoch [65/100], Loss: 0.2245\n",
      "Epoch [66/100], Loss: 0.2237\n",
      "Epoch [67/100], Loss: 0.2229\n",
      "Epoch [68/100], Loss: 0.2221\n",
      "Epoch [69/100], Loss: 0.2212\n",
      "Epoch [70/100], Loss: 0.2204\n",
      "Epoch [71/100], Loss: 0.2196\n",
      "Epoch [72/100], Loss: 0.2188\n",
      "Epoch [73/100], Loss: 0.2180\n",
      "Epoch [74/100], Loss: 0.2172\n",
      "Epoch [75/100], Loss: 0.2164\n",
      "Epoch [76/100], Loss: 0.2157\n",
      "Epoch [77/100], Loss: 0.2149\n",
      "Epoch [78/100], Loss: 0.2143\n",
      "Epoch [79/100], Loss: 0.2137\n",
      "Epoch [80/100], Loss: 0.2132\n",
      "Epoch [81/100], Loss: 0.2126\n",
      "Epoch [82/100], Loss: 0.2122\n",
      "Epoch [83/100], Loss: 0.2117\n",
      "Epoch [84/100], Loss: 0.2112\n",
      "Epoch [85/100], Loss: 0.2108\n",
      "Epoch [86/100], Loss: 0.2105\n",
      "Epoch [87/100], Loss: 0.2102\n",
      "Epoch [88/100], Loss: 0.2099\n",
      "Epoch [89/100], Loss: 0.2097\n",
      "Epoch [90/100], Loss: 0.2094\n",
      "Epoch [91/100], Loss: 0.2092\n",
      "Epoch [92/100], Loss: 0.2090\n",
      "Epoch [93/100], Loss: 0.2087\n",
      "Epoch [94/100], Loss: 0.2085\n",
      "Epoch [95/100], Loss: 0.2083\n",
      "Epoch [96/100], Loss: 0.2080\n",
      "Epoch [97/100], Loss: 0.2078\n",
      "Epoch [98/100], Loss: 0.2077\n",
      "Epoch [99/100], Loss: 0.2075\n",
      "Epoch [100/100], Loss: 0.2073\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple RNN model\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        return out\n",
    "\n",
    "# Instantiate the model\n",
    "input_size = 10  # Replace with your input size\n",
    "hidden_size = 20  # Replace with your desired hidden size\n",
    "num_layers = 2  # Replace with the number of layers\n",
    "model = SimpleRNN(input_size, hidden_size, num_layers)\n",
    "\n",
    "# Define toy sequence data and target\n",
    "sequence = torch.randn(5, 3, input_size)  # Replace 5 with the batch size\n",
    "target = torch.randn(5, 3, hidden_size)  # Use hidden_size for the target\n",
    "\n",
    "# Loss and optimization\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(sequence)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
