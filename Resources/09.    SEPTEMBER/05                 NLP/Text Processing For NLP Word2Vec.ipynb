{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing neccessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Word2Vec is a popular model for creating word embeddings. It captures semantic relationships between words.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize into sentences and words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize into sentences and words\n",
      "Tokenized sentences: [['word2vec', 'is', 'a', 'popular', 'model', 'for', 'creating', 'word', 'embeddings', '.'], ['it', 'captures', 'semantic', 'relationships', 'between', 'words', '.']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenize into sentences and words\")\n",
    "sentences = sent_tokenize(text)\n",
    "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
    "print(\"Tokenized sentences:\", tokenized_sentences)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Word2Vec model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train the Word2Vec model\n",
      "Word2Vec model trained successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train the Word2Vec model\")\n",
    "model = Word2Vec(tokenized_sentences, vector_size=100, window=5, min_count=1, sg=0)\n",
    "print(\"Word2Vec model trained successfully\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access word vectors\n",
      "Vector for 'word2vec': [-7.1947388e-03  4.2369105e-03  2.1634006e-03  7.4431021e-03\n",
      " -4.8892787e-03 -4.5648082e-03 -6.0973302e-03  3.2960486e-03\n",
      " -4.5027356e-03  8.5229622e-03 -4.2892229e-03 -9.1053341e-03\n",
      " -4.8158765e-03  6.4141168e-03 -6.3667730e-03 -5.2594147e-03\n",
      " -7.3036160e-03  6.0228016e-03  3.3553250e-03  2.8453341e-03\n",
      " -3.1368493e-03  6.0344539e-03 -6.1484994e-03 -1.9810209e-03\n",
      " -5.9811068e-03 -9.9241280e-04 -2.0243337e-03  8.4827086e-03\n",
      "  7.7920427e-05 -8.5749160e-03 -5.4264371e-03 -6.8757343e-03\n",
      "  2.6954534e-03  9.4571207e-03 -5.8147698e-03  8.2650138e-03\n",
      "  8.5289059e-03 -7.0587867e-03 -8.8826800e-03  9.4666099e-03\n",
      "  8.3740726e-03 -4.6912651e-03 -6.7250021e-03  7.8432476e-03\n",
      "  3.7632957e-03  8.0927592e-03 -7.5729280e-03 -9.5244488e-03\n",
      "  1.5787388e-03 -9.8072886e-03 -4.8867702e-03 -3.4599674e-03\n",
      "  9.6200965e-03  8.6221807e-03 -2.8354356e-03  5.8279303e-03\n",
      "  8.2378937e-03 -2.2627739e-03  9.5293736e-03  7.1610785e-03\n",
      "  2.0418831e-03 -3.8485024e-03 -5.0787819e-03 -3.0490856e-03\n",
      "  7.8875972e-03 -6.1902185e-03 -2.9149065e-03  9.1945054e-03\n",
      "  3.4555281e-03  6.0723778e-03 -8.0352426e-03 -7.5231306e-04\n",
      "  5.5222996e-03 -4.7121798e-03  7.4783945e-03  9.3205022e-03\n",
      " -4.1066855e-04 -2.0645272e-03 -5.9447472e-04 -5.7882112e-03\n",
      " -8.3866492e-03 -1.5099728e-03 -2.5544283e-03  4.3842816e-03\n",
      " -6.8651936e-03  5.4148114e-03 -6.7423265e-03 -7.8193648e-03\n",
      "  8.4718093e-03  8.9177694e-03 -3.4802472e-03  3.4930378e-03\n",
      " -5.7954262e-03 -8.7501695e-03 -5.5147889e-03  6.7495820e-03\n",
      "  6.4202491e-03  9.4385901e-03  7.0555722e-03  6.7555695e-03]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Access word vectors\")\n",
    "word_vectors = model.wv\n",
    "vector = word_vectors['word2vec']\n",
    "print(\"Vector for 'word2vec':\", vector)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding similar words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding similar words\n",
      "Similar words to 'model': [('between', 0.17272792756557465), ('captures', 0.16697382926940918), ('embeddings', 0.11113201081752777)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Finding similar words\")\n",
    "similar_words = model.wv.most_similar('model', topn=3)\n",
    "print(\"Similar words to 'model':\", similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
