{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Word embeddings are essential in NLP tasks. They capture semantic relationships between words.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize into sentences and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize into sentences and words\n",
      "Tokenized sentences: [['word', 'embeddings', 'are', 'essential', 'in', 'nlp', 'tasks', '.'], ['they', 'capture', 'semantic', 'relationships', 'between', 'words', '.']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenize into sentences and words\")\n",
    "sentences = sent_tokenize(text)\n",
    "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
    "print(\"Tokenized sentences:\", tokenized_sentences)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Word2Vec Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train the Word2Vec model\n",
      "Word2Vec model trained successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train the Word2Vec model\")\n",
    "model = Word2Vec(tokenized_sentences, vector_size=100, window=5, min_count=1, sg=0)\n",
    "print(\"Word2Vec model trained successfully\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access word vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access word vectors\n",
      "Vector for 'word': [-0.00950012  0.00956222 -0.00777076 -0.00264551 -0.00490641 -0.0049667\n",
      " -0.00802359 -0.00778358 -0.00455321 -0.00127536 -0.00510299  0.00614054\n",
      " -0.00951662 -0.0053071   0.00943715  0.00699133  0.00767582  0.00423474\n",
      "  0.00050709 -0.00598114  0.00601878  0.00263503  0.00769943  0.00639384\n",
      "  0.00794257  0.00865741 -0.00989575 -0.0067557   0.00133757  0.0064403\n",
      "  0.00737382  0.00551698  0.00766163 -0.00512557  0.00658441 -0.00410837\n",
      " -0.00905534  0.00914168  0.0013314  -0.00275968 -0.00247784 -0.00422048\n",
      "  0.00481234  0.00440022 -0.00265336 -0.00734188 -0.00356585 -0.00033661\n",
      "  0.00609589 -0.00283734 -0.00012089  0.00087973 -0.00709565  0.002065\n",
      " -0.00143242  0.00280215  0.00484222 -0.00135202 -0.00278014  0.00773865\n",
      "  0.0050456   0.00671352  0.00451564  0.00866716  0.00747497 -0.00108189\n",
      "  0.00874764  0.00460172  0.00544063 -0.00138608 -0.00204132 -0.00442435\n",
      " -0.0085152   0.00303773  0.00888319  0.00891974 -0.00194235  0.00608616\n",
      "  0.00377972 -0.00429597  0.00204292 -0.00543789  0.00820889  0.00543291\n",
      "  0.00318443  0.00410257  0.00865715  0.00727203 -0.00083347 -0.00707277\n",
      "  0.00838047  0.00723358  0.00173047 -0.00134749 -0.00589009 -0.00453309\n",
      "  0.00864797 -0.00313511 -0.00633882  0.00987008]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Access word vectors\")\n",
    "word_vectors = model.wv\n",
    "vector = word_vectors['word']\n",
    "print(\"Vector for 'word':\", vector)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding similar words\n",
      "Similar words to 'embeddings': [('semantic', 0.1501718908548355), ('essential', 0.12813477218151093), ('.', 0.0931011438369751)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Finding similar words\")\n",
    "similar_words = model.wv.most_similar('embeddings', topn=3)\n",
    "print(\"Similar words to 'embeddings':\", similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
